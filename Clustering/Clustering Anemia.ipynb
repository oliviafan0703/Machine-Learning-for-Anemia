{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c34d52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "# from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e0068fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/Users/oliviafan/Downloads/Data/resized-D1\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "nail_beds = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.jpg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            nail_beds.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee446bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the image as a 224x224 array\n",
    "img = load_img(nail_beds[0], target_size=(224,224))\n",
    "# convert from 'JPG.Image.Image' to numpy array\n",
    "img = np.array(img)\n",
    "print(img.shape)\n",
    "(224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08e588a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_img = img.reshape(1,224,224,3)\n",
    "print(reshaped_img.shape)\n",
    "(1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39ac362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_input(reshaped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a4907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 56s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = VGG16()\n",
    "# remove the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cafb96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 621ms/step\n",
      "(1, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model.predict(reshaped_img)\n",
    "print(features.shape)\n",
    "(1,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9143f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n",
      "(1, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = model.predict(reshaped_img)\n",
    "print(features.shape)\n",
    "(1,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7d8070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the model first and pass as an argument\n",
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'JPG.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a774ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {}\n",
    "p = r\"/Users/oliviafan/Downloads/Data/resized-D1\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for nail in nail_beds:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(nail,model)\n",
    "        data[nail] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "          \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys())) \n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e117e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 1, 4096)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93674775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape so that there are 93 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "\n",
    "# # get the unique labels (from the flower_labels.csv)\n",
    "# df = pd.read_csv('flower_labels.csv')\n",
    "# label = df['label'].tolist()\n",
    "# unique_labels = list(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f51f541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 4096)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c2188bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=90, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4513108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA: 4096\n",
      "Components after PCA: 90\n"
     ]
    }
   ],
   "source": [
    "print(f\"Components before PCA: {feat.shape[1]}\")\n",
    "print(f\"Components after PCA: {pca.n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6d473a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviafan/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5, n_jobs=-1, random_state=22)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters = num, n_jobs=-1, random_state=22)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04ca0661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2, 4, 1, 3, 3, 2, 0, 4, 4, 2, 2,\n",
       "       2, 2, 4, 1, 1, 1, 4, 4, 4, 4, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 4, 1, 2, 1, 4, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1,\n",
       "       1, 4, 2, 1, 1, 4, 1, 1, 4, 2, 1, 1, 1, 0, 0, 1, 2, 2, 0, 1, 0, 4,\n",
       "       4, 2, 2, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2efa5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holds the cluster id and the images { id: [images] }\n",
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "pth = \"/Users/oliviafan/Downloads\"\n",
    "torch.save(groups, '{}/result.pkl'.format(pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d82e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
